{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70fb1423-aaa3-4e44-81e3-54bba947220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_summary(summary):\n",
    "    bowler = \"N/A\"\n",
    "    batsman = \"N/A\"\n",
    "    runs = 0\n",
    "    is_wicket = False\n",
    "    bowler_score = 0  \n",
    "    \n",
    "    try:\n",
    "        if \" to \" in summary:\n",
    "            parts = summary.split(\" to \", 1)\n",
    "            bowler = parts[0].strip()\n",
    "            rest = parts[1].strip()\n",
    "            \n",
    "            if \",\" in rest:\n",
    "                subparts = rest.split(\",\", 1)\n",
    "                batsman = subparts[0].strip()\n",
    "                outcome = subparts[1].strip()\n",
    "                \n",
    "                if \"OUT\" in outcome or \"WICKET\" in outcome:\n",
    "                    runs = 0\n",
    "                    is_wicket = True\n",
    "                    bowler_score = 5  # +5 for a wicket\n",
    "                elif outcome == \"no run\":\n",
    "                    runs = 0\n",
    "                    bowler_score = 1  # +1 for no run\n",
    "                elif \"FOUR\" in outcome or \"4 run\" in outcome:\n",
    "                    runs = 4\n",
    "                    bowler_score = -2  # -2 for a four\n",
    "                elif \"SIX\" in outcome or \"6 run\" in outcome:\n",
    "                    runs = 6\n",
    "                    bowler_score = -3  # -3 for a six\n",
    "                elif \"leg bye\" in outcome or \"bye\" in outcome:\n",
    "                    if \"leg bye\" in outcome:\n",
    "                        match = re.search(r'(\\d+) leg bye', outcome)\n",
    "                        runs = int(match.group(1)) if match else 1\n",
    "                    else:  # regular bye\n",
    "                        match = re.search(r'(\\d+) bye', outcome)\n",
    "                        runs = int(match.group(1)) if match else 1\n",
    "                    bowler_score = -0.25  # -0.25 for leg bye or bye\n",
    "                elif \"wide\" in outcome:\n",
    "                    # Wides are always at least 1 run\n",
    "                    match = re.search(r'(\\d+) wide', outcome)\n",
    "                    runs = int(match.group(1)) if match else 1\n",
    "                    bowler_score = -1  # -1 for wide\n",
    "                elif \"no ball\" in outcome:\n",
    "                    # No balls are 1 run plus any runs scored\n",
    "                    runs = 1  # Start with 1 for the no ball\n",
    "                    \n",
    "                    # Check if additional runs were scored\n",
    "                    run_match = re.search(r'(\\d+) run', outcome)\n",
    "                    if run_match:\n",
    "                        runs += int(run_match.group(1))\n",
    "                    bowler_score = -1  # -1 for no ball (similar to wide)\n",
    "                # Regular runs\n",
    "                else:\n",
    "                    match = re.search(r'(\\d+) run', outcome)\n",
    "                    if match:\n",
    "                        runs = int(match.group(1))\n",
    "                        # For regular runs (not 0, 4, or 6)\n",
    "                        if runs > 0:\n",
    "                            bowler_score = -runs / 2  # Negative score proportional to runs\n",
    "        \n",
    "        return bowler, batsman, runs, is_wicket, bowler_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing summary: {e}\")\n",
    "        return \"N/A\", \"N/A\", 0, False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4a1920-be67-46fa-b4f6-e89aec7c6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw_data(df):\n",
    "    if df[\"Ball Number\"].dtype == 'object':\n",
    "        df[[\"over_str\", \"ball_str\"]] = df[\"Ball Number\"].str.split(\".\", expand=True)\n",
    "        df[\"over\"] = pd.to_numeric(df[\"over_str\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "        df[\"ball\"] = pd.to_numeric(df[\"ball_str\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "        \n",
    "        df[\"sort_order\"] = df[\"over\"] * 6 + df[\"ball\"]\n",
    "        df = df.sort_values(by=[\"sort_order\"]).reset_index(drop=True)\n",
    "        df = df.drop(columns=[\"over_str\", \"ball_str\", \"sort_order\"])\n",
    "    \n",
    "    df[\"Ball\"] = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c3dec8-af4a-4457-b254-b1f7bb2aa540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_commentary_data(page_source):\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    \n",
    "    ball_containers = soup.find_all(\"div\", class_=lambda x: x and \"ds-text-tight-l\" in x and \"ds-flex\" in x)\n",
    "    \n",
    "    ball_numbers = []\n",
    "    summaries = []\n",
    "    descriptions = []\n",
    "    \n",
    "    for container in ball_containers:\n",
    "        ball_span = container.find(\"span\", class_=\"ds-text-tight-s ds-font-regular ds-mb-1 lg:ds-mb-0 lg:ds-mr-3 ds-block ds-text-center ds-text-typo-mid1\")\n",
    "        ball_text = ball_span.get_text(strip=True) if ball_span else \"N/A\"\n",
    "        \n",
    "        summary_div = container.find(\"div\", class_=\"ds-leading-[16px] lg:ds-leading-none ds-mb-0.5\")\n",
    "        summary_text = summary_div.get_text(strip=True) if summary_div else \"N/A\"\n",
    "        \n",
    "        desc_p = container.find(\"p\", class_=\"ci-html-content first-letter:ds-capitalize ds-leading-[24px]\")\n",
    "        desc_text = desc_p.get_text(strip=True) if desc_p else \"N/A\"\n",
    "        \n",
    "        ball_numbers.append(ball_text)\n",
    "        summaries.append(summary_text)\n",
    "        descriptions.append(desc_text)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"Ball Number\": ball_numbers,\n",
    "        \"Summary\": summaries,\n",
    "        \"Description\": descriptions\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328e67c5-0750-4e90-b890-f086795a5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_match_data(df, match_id, target, city):\n",
    "    # Apply the parse_summary function to extract data from the summary\n",
    "    parsed_data = df[\"Summary\"].apply(parse_summary)\n",
    "    df['bowler'], df['batsman'], df['Runs'], df['is_wicket'], df['bowler_score'] = zip(*parsed_data)\n",
    "    \n",
    "    # Evaluate bowler performance for each ball\n",
    "    df['bowler_good'] = df.apply(lambda row: 1 if row['bowler_score'] > 0 else 0, axis=1)\n",
    "    \n",
    "    # Ensure Runs column is numeric\n",
    "    df['Runs'] = pd.to_numeric(df['Runs'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Add metadata\n",
    "    df['match_id'] = match_id\n",
    "    df['city'] = city\n",
    "    \n",
    "    # Identify extras and calculate legal deliveries\n",
    "    df['is_extra'] = df['Summary'].str.contains(r'wide|no ball', case=False, regex=True)\n",
    "    df['legal_delivery'] = ~df['is_extra']\n",
    "    df['legal_deliveries_count'] = df['legal_delivery'].cumsum()\n",
    "    \n",
    "    # Calculate overs properly based on legal deliveries\n",
    "    df['overs_completed'] = (df['legal_deliveries_count'] - 1) // 6\n",
    "    df['balls_in_current_over'] = ((df['legal_deliveries_count'] - 1) % 6) + 1\n",
    "    \n",
    "    # Handle the case where legal_deliveries_count is 0 (first ball)\n",
    "    df.loc[df['legal_deliveries_count'] == 0, 'overs_completed'] = 0\n",
    "    df.loc[df['legal_deliveries_count'] == 0, 'balls_in_current_over'] = 0\n",
    "    \n",
    "    # Calculate decimal overs\n",
    "    df['overs_bowled'] = df['overs_completed'] + (df['balls_in_current_over'] / 6)\n",
    "    df['overs_completed'] = df['overs_completed'].clip(lower=0)\n",
    "    df['overs_bowled'] = df['overs_bowled'].clip(lower=0)\n",
    "    \n",
    "    # Calculate run statistics\n",
    "    df['total_runs'] = df['Runs'].cumsum()\n",
    "    df['current_run_rate'] = df.apply(\n",
    "        lambda row: row['total_runs'] / max(row['overs_bowled'], 0.1) if row['overs_bowled'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Add match metadata and calculate target-related stats\n",
    "    total_overs = 20  # Standard T20 match\n",
    "    df['total_overs'] = total_overs\n",
    "    df['target'] = target\n",
    "    df['runs_needed'] = np.maximum(target - df['total_runs'], 0)\n",
    "    df['overs_remaining'] = np.maximum(df['total_overs'] - df['overs_bowled'], 0)\n",
    "    \n",
    "    # Calculate required run rate\n",
    "    df['required_run_rate'] = df.apply(\n",
    "        lambda row: row['runs_needed'] / np.maximum(row['overs_remaining'], 0.1) \n",
    "                    if row['overs_remaining'] > 0 else float('inf'),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Calculate wicket statistics\n",
    "    df['wickets_fallen'] = df['is_wicket'].cumsum()\n",
    "    df['wickets_in_hand'] = 10 - df['wickets_fallen']\n",
    "    \n",
    "    # Clean up unnecessary columns\n",
    "    df = df.drop(columns=['Summary', 'balls_in_current_over', 'Description', 'bowler_good'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b8638e-e01d-4f4b-9324-a54959938ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import urllib3, socket\n",
    "from urllib3.connection import HTTPConnection\n",
    "    \n",
    "def extraction2(url, target, id, city):\n",
    "    print(\"Starting extraction...\")\n",
    "    match_id = id\n",
    "    HTTPConnection.default_socket_options = ( \n",
    "            HTTPConnection.default_socket_options + [\n",
    "            (socket.SOL_SOCKET, socket.SO_SNDBUF, 1000000), #1MB in byte\n",
    "            (socket.SOL_SOCKET, socket.SO_RCVBUF, 1000000)\n",
    "        ])\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    #chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.set_page_load_timeout(300)  # Increased timeout\n",
    "    driver.set_script_timeout(300)     # Increased timeout\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            WebDriverWait(driver, 60).until(  # Increased wait time\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.ds-text-tight-l.ds-flex\"))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error waiting for page to load: {e}\")\n",
    "            driver.quit()\n",
    "            return None\n",
    "        \n",
    "        scroll_pause_time = 1\n",
    "        \n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollBy({ top: 200, behavior: 'smooth' });\")\n",
    "            time.sleep(0.2) \n",
    "                    \n",
    "            # Check for the presence of \"0.1\" in ball numbers\n",
    "            ball_spans = driver.find_elements(By.CSS_SELECTOR, \"span.ds-text-tight-s.ds-font-regular.ds-mb-1.lg\\\\:ds-mb-0.lg\\\\:ds-mr-3.ds-block.ds-text-center.ds-text-typo-mid1\")\n",
    "            ball_texts = [span.text.strip() for span in ball_spans if span.text.strip()]\n",
    "            if \"0.1\" in ball_texts:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        time.sleep(2)\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "            print(\"Browser closed\")\n",
    "        except:\n",
    "            print(\"Error closing browser\")\n",
    "\n",
    "    \n",
    "    df = extract_commentary_data(page_source)\n",
    "    df.to_csv(\"cricket_commentary_raw.csv\", index=False)\n",
    "    \n",
    "    try:\n",
    "        df = preprocess_raw_data(df)\n",
    "        df.to_csv(\"commentary_processed.csv\", index=False)\n",
    "        \n",
    "        df = analyze_match_data(df, int(id), int(target), city)\n",
    "        \n",
    "        # Save the final processed commentary CSV\n",
    "        df.to_csv(\"processed_cricket_commentary.csv\", index=False)\n",
    "        print(\"Final processed dataset saved as 'processed_cricket_commentary.csv'.\")\n",
    "        \n",
    "        # Save the enhanced dataset with metadata calculations\n",
    "        filename = f\"{match_id}b.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Dataset saved as '{filename}'.\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing cricket commentary: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdbdc8c2-9df5-4f10-8bb8-5536615fba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import urllib3, socket\n",
    "from urllib3.connection import HTTPConnection\n",
    "\n",
    "def extraction1(url, target, id, city):\n",
    "    print(\"Starting extraction...\")\n",
    "    match_id = id\n",
    "    HTTPConnection.default_socket_options = ( \n",
    "            HTTPConnection.default_socket_options + [\n",
    "            (socket.SOL_SOCKET, socket.SO_SNDBUF, 1000000), #1MB in byte\n",
    "            (socket.SOL_SOCKET, socket.SO_RCVBUF, 1000000)\n",
    "        ])\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    #chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.set_page_load_timeout(300)  # Increased timeout\n",
    "    driver.set_script_timeout(300)     # Increased timeout\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            WebDriverWait(driver, 60).until(  # Increased wait time\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.ds-text-tight-l.ds-flex\"))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error waiting for page to load: {e}\")\n",
    "            driver.quit()\n",
    "            return None\n",
    "            \n",
    "        # Add click functionality for innings selection\n",
    "        try:\n",
    "            innings_dropdown_trigger = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_all_elements_located((By.CLASS_NAME, \"ds-popper-wrapper\"))\n",
    "            )\n",
    "            \n",
    "            dropdown = innings_dropdown_trigger[1]\n",
    "            print(\"Got dropdown\", dropdown)\n",
    "            dropdown.click()\n",
    "            print(\"Innings dropdown opened.\")\n",
    "            \n",
    "            # Locate the innings options within the popup\n",
    "            innings_options = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, \"//div[@data-tippy-root]//li[@class='ds-w-full ds-flex']\"))\n",
    "            )\n",
    "            print(f\"Found {len(innings_options)} innings options in popup.\")\n",
    "            \n",
    "            # Click the first innings tab\n",
    "            if len(innings_options) >= 1:\n",
    "                first_innings_tab = innings_options[0]  # First option (index 0)\n",
    "                tab_title = first_innings_tab.get_attribute(\"title\")\n",
    "                print(f\"First innings tab identified: {tab_title}\")\n",
    "                try:\n",
    "                    first_innings_tab.click()\n",
    "                    print(\"First innings tab clicked.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to click tab: {e}\")\n",
    "                    driver.execute_script(\"arguments[0].click();\", first_innings_tab)  # Fallback\n",
    "                    print(\"Clicked via JavaScript fallback.\")\n",
    "            else:\n",
    "                print(\"No innings options found in popup.\")\n",
    "            \n",
    "            # Wait for the first innings commentary to load\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"ds-leading-[16px]\"))\n",
    "            )\n",
    "            print(\"First innings commentary loaded successfully.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error selecting innings: {e}\")\n",
    "            # Continue with the script even if innings selection fails\n",
    "        \n",
    "        # Original scroll code\n",
    "        scroll_pause_time = 1\n",
    "        \n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollBy({ top: 200, behavior: 'smooth' });\")\n",
    "            time.sleep(0.2) \n",
    "                    \n",
    "            # Check for the presence of \"0.1\" in ball numbers\n",
    "            ball_spans = driver.find_elements(By.CSS_SELECTOR, \"span.ds-text-tight-s.ds-font-regular.ds-mb-1.lg\\\\:ds-mb-0.lg\\\\:ds-mr-3.ds-block.ds-text-center.ds-text-typo-mid1\")\n",
    "            ball_texts = [span.text.strip() for span in ball_spans if span.text.strip()]\n",
    "            if \"0.1\" in ball_texts:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        time.sleep(2)\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "            print(\"Browser closed\")\n",
    "        except:\n",
    "            print(\"Error closing browser\")\n",
    "    \n",
    "    df = extract_commentary_data(page_source)\n",
    "    df.to_csv(\"cricket_commentary_raw.csv\", index=False)\n",
    "    \n",
    "    try:\n",
    "        df = preprocess_raw_data(df)\n",
    "        df.to_csv(\"commentary_processed.csv\", index=False)\n",
    "        \n",
    "        df = analyze_match_data(df, int(id), int(target), city)\n",
    "        \n",
    "        # Save the final processed commentary CSV\n",
    "        df.to_csv(\"processed_cricket_commentary.csv\", index=False)\n",
    "        print(\"Final processed dataset saved as 'processed_cricket_commentary.csv'.\")\n",
    "        \n",
    "        # Save the enhanced dataset with metadata calculations\n",
    "        filename = f\"{match_id}a.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Dataset saved as '{filename}'.\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing cricket commentary: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a089ff3-48b4-4760-b913-ff13d269557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the script stopped previously, you can resume from a specific match.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the match number to start from (or press Enter to start from 1):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping from match number 1\n",
      "Starting script to fetch target scores and commentary URLs...\n",
      "Found 74 match containers.\n",
      "\n",
      "Processing match 1...\n",
      "Starting extraction...\n",
      "Browser closed\n",
      "Final processed dataset saved as 'processed_cricket_commentary.csv'.\n",
      "Dataset saved as '1b.csv'.\n",
      "Starting extraction...\n",
      "Got dropdown <selenium.webdriver.remote.webelement.WebElement (session=\"57b0c0031d56625256307cdac082d8d5\", element=\"f.861C03155102765E6CCEC75CA5D0E805.d.86A7D846D0B592BCD7E341BEA01E8D29.e.39\")>\n",
      "Innings dropdown opened.\n",
      "Found 2 innings options in popup.\n",
      "First innings tab identified: CSK \n",
      "First innings tab clicked.\n",
      "Error selecting innings: Message: invalid selector: An invalid or illegal selector was specified\n",
      "  (Session info: chrome=134.0.6998.35); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalid-selector-exception\n",
      "Stacktrace:\n",
      "#0 0x5ca761fecffa <unknown>\n",
      "#1 0x5ca761aab970 <unknown>\n",
      "#2 0x5ca761ab250e <unknown>\n",
      "#3 0x5ca761ab4d58 <unknown>\n",
      "#4 0x5ca761ab4de3 <unknown>\n",
      "#5 0x5ca761afce52 <unknown>\n",
      "#6 0x5ca761afd5b1 <unknown>\n",
      "#7 0x5ca761b4c3c4 <unknown>\n",
      "#8 0x5ca761b232bd <unknown>\n",
      "#9 0x5ca761b4970c <unknown>\n",
      "#10 0x5ca761b23063 <unknown>\n",
      "#11 0x5ca761aef328 <unknown>\n",
      "#12 0x5ca761af0491 <unknown>\n",
      "#13 0x5ca761fb442b <unknown>\n",
      "#14 0x5ca761fb82ec <unknown>\n",
      "#15 0x5ca761f9ba22 <unknown>\n",
      "#16 0x5ca761fb8e64 <unknown>\n",
      "#17 0x5ca761f7fbef <unknown>\n",
      "#18 0x5ca761fdb558 <unknown>\n",
      "#19 0x5ca761fdb736 <unknown>\n",
      "#20 0x5ca761febe76 <unknown>\n",
      "#21 0x7483e409caa4 <unknown>\n",
      "#22 0x7483e4129c3c <unknown>\n",
      "\n",
      "Browser closed\n",
      "Final processed dataset saved as 'processed_cricket_commentary.csv'.\n",
      "Dataset saved as '1a.csv'.\n",
      "\n",
      "Processing match 2...\n",
      "Starting extraction...\n",
      "Browser closed\n",
      "Closing browser in 5 seconds...\n",
      "Browser closed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m start_match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(user_input) \u001b[38;5;28;01mif\u001b[39;00m user_input \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting scraping from match number \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_match\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m match_details \u001b[38;5;241m=\u001b[39m get_target_and_commentary_urls(schedule_url, start_match)\n",
      "Cell \u001b[0;32mIn[10], line 70\u001b[0m, in \u001b[0;36mget_target_and_commentary_urls\u001b[0;34m(url, start_match)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Append all data, including city\u001b[39;00m\n\u001b[1;32m     63\u001b[0m extracted_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_id\u001b[39m\u001b[38;5;124m'\u001b[39m: match_id,\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m: city,\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_score\u001b[39m\u001b[38;5;124m'\u001b[39m: target,\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommentary_url\u001b[39m\u001b[38;5;124m'\u001b[39m: commentary_url\n\u001b[1;32m     68\u001b[0m })\n\u001b[0;32m---> 70\u001b[0m extraction2(commentary_url, target, match_id, city)\n\u001b[1;32m     71\u001b[0m extraction1(commentary_url, target, match_id, city)\n\u001b[1;32m     72\u001b[0m match_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m, in \u001b[0;36mextraction2\u001b[0;34m(url, target, id, city)\u001b[0m\n\u001b[1;32m     31\u001b[0m driver\u001b[38;5;241m.\u001b[39mset_script_timeout(\u001b[38;5;241m300\u001b[39m)     \u001b[38;5;66;03m# Increased timeout\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         WebDriverWait(driver, \u001b[38;5;241m60\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(  \u001b[38;5;66;03m# Increased wait time\u001b[39;00m\n\u001b[1;32m     37\u001b[0m             EC\u001b[38;5;241m.\u001b[39mpresence_of_element_located((By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv.ds-text-tight-l.ds-flex\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     38\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:454\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Navigate the browser to the specified URL in the current window or\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    tab.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    >>> driver.get(\"https://example.com\")\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:427\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    425\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(command_info[\u001b[38;5;241m0\u001b[39m], url, body\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[1;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    136\u001b[0m         method,\n\u001b[1;32m    137\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[1;32m    144\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m    145\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/http/client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "def get_target_and_commentary_urls(url, start_match=1):\n",
    "    print(\"Starting script to fetch target scores and commentary URLs...\")\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow time for page to load fully\n",
    "    \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        matches = soup.find_all('div', class_='ds-p-4 ds-border-y ds-border-line')\n",
    "        print(f\"Found {len(matches)} match containers.\")\n",
    "        \n",
    "        extracted_data = []\n",
    "        match_id = start_match\n",
    "        \n",
    "        for match in matches[start_match-1:]:\n",
    "            print(f\"\\nProcessing match {match_id}...\")\n",
    "            link_tag = match.find('a', href=True)\n",
    "            if not link_tag:\n",
    "                print(\"No link tag found; skipping this match.\")\n",
    "                match_id += 1\n",
    "                continue\n",
    "            original_url = 'https://www.espncricinfo.com' + link_tag['href']\n",
    "            \n",
    "            url_parts = original_url.split('/')\n",
    "            url_parts[-1] = 'ball-by-ball-commentary'\n",
    "            commentary_url = '/'.join(url_parts)\n",
    "            \n",
    "            # Extract the city\n",
    "            city = None\n",
    "            details_div = match.find('div', class_='ds-text-tight-s ds-font-regular ds-truncate ds-text-typo-mid3')\n",
    "            if details_div:\n",
    "                span = details_div.find('span', class_='ds-text-tight-s ds-font-medium ds-text-typo')\n",
    "                if span:\n",
    "                    next_text = span.next_sibling\n",
    "                    if next_text and isinstance(next_text, str):\n",
    "                        city_part = next_text.strip().lstrip('•').strip()\n",
    "                        city = city_part.split(',')[0].strip()\n",
    "            \n",
    "            # Extract target as before\n",
    "            target = None\n",
    "            team_scores = match.find_all('div', class_='ci-team-score')\n",
    "            for score_div in team_scores:\n",
    "                score_text_div = score_div.find('div', class_='ds-text-compact-s ds-text-typo ds-text-right ds-whitespace-nowrap')\n",
    "                if score_text_div:\n",
    "                    target_span = score_text_div.find('span', class_='ds-text-compact-xs ds-mr-0.5')\n",
    "                    if target_span and target_span.text.strip():\n",
    "                        target_match = re.search(r'T:(\\d+)', target_span.text)\n",
    "                        if target_match:\n",
    "                            target = int(target_match.group(1))\n",
    "                            break\n",
    "            \n",
    "            if target is None:\n",
    "                target = 0\n",
    "                print(\"No target score found for this match.\")\n",
    "            \n",
    "            # Append all data, including city\n",
    "            extracted_data.append({\n",
    "                'match_id': match_id,\n",
    "                'city': city,\n",
    "                'target_score': target,\n",
    "                'commentary_url': commentary_url\n",
    "            })\n",
    "            \n",
    "            extraction2(commentary_url, target, match_id, city)\n",
    "            extraction1(commentary_url, target, match_id, city)\n",
    "            match_id += 1\n",
    "        \n",
    "        print(\"\\nData extraction complete.\")\n",
    "        return extracted_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return extracted_data  \n",
    "    \n",
    "    finally:\n",
    "        print(\"Closing browser in 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "        driver.quit()\n",
    "        print(\"Browser closed.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    schedule_url = \"https://www.espncricinfo.com/series/indian-premier-league-2023-1345038/match-schedule-fixtures-and-results\"\n",
    "    print(\"If the script stopped previously, you can resume from a specific match.\")\n",
    "    user_input = input(\"Enter the match number to start from (or press Enter to start from 1): \")        \n",
    "    start_match = int(user_input) if user_input else 1\n",
    "    \n",
    "    print(f\"Starting scraping from match number {start_match}\")\n",
    "    match_details = get_target_and_commentary_urls(schedule_url, start_match)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab224b1-493a-47c0-95c9-80e05e297622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
