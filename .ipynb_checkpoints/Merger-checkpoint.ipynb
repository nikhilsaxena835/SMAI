{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e27588-5938-479a-bd65-a775adadf127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year: 2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2015: 100%|██████████████| 59/59 [00:00<00:00, 281.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2015.csv with 13659 rows.\n",
      "\n",
      "Processing year: 2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2016: 100%|██████████████| 60/60 [00:00<00:00, 280.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2016.csv with 14094 rows.\n",
      "\n",
      "Processing year: 2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2017: 100%|██████████████| 59/59 [00:00<00:00, 291.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2017.csv with 13741 rows.\n",
      "\n",
      "Processing year: 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2018: 100%|██████████████| 60/60 [00:00<00:00, 285.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2018.csv with 14286 rows.\n",
      "\n",
      "Processing year: 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2019: 100%|██████████████| 60/60 [00:00<00:00, 241.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2019.csv with 14067 rows.\n",
      "\n",
      "Processing year: 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2020: 100%|██████████████| 60/60 [00:00<00:00, 291.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2020.csv with 14053 rows.\n",
      "\n",
      "Processing year: 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2021: 100%|██████████████| 60/60 [00:00<00:00, 294.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2021.csv with 14300 rows.\n",
      "\n",
      "Processing year: 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2022: 100%|██████████████| 74/74 [00:00<00:00, 282.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2022.csv with 17912 rows.\n",
      "\n",
      "Processing year: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2023: 100%|██████████████| 58/58 [00:00<00:00, 283.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2023.csv with 14147 rows.\n",
      "\n",
      "Processing year: 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Merging matches for 2024: 100%|██████████████| 56/56 [00:00<00:00, 292.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Updated_dataset/dataset/yearly_merged/2024.csv with 13564 rows.\n",
      "\n",
      "✅ Final combined dataset saved at: Updated_dataset/dataset/all_years_combined.csv with 143823 rows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to the dataset folder\n",
    "base_path = 'Updated_dataset/dataset'\n",
    "\n",
    "# Output folder for merged year files\n",
    "output_path = os.path.join(base_path, 'yearly_merged')\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# List of years\n",
    "years = [str(year) for year in range(2015, 2025)]\n",
    "\n",
    "# Store final dataframes for all years\n",
    "all_years_data = []\n",
    "\n",
    "for year in years:\n",
    "    print(f\"\\nProcessing year: {year}\")\n",
    "    \n",
    "    year_path = os.path.join(base_path, year)\n",
    "    if not os.path.isdir(year_path):\n",
    "        print(f\"Skipped {year} — folder not found.\")\n",
    "        continue\n",
    "\n",
    "    # List of all files\n",
    "    files = os.listdir(year_path)\n",
    "    a_files = sorted([f for f in files if f.endswith('a.csv')])\n",
    "    b_files = sorted([f for f in files if f.endswith('b.csv')])\n",
    "\n",
    "    # Mapping from match number to files\n",
    "    match_ids = sorted(set(f[:-5] for f in a_files if f[:-5] + 'b.csv' in b_files))\n",
    "\n",
    "    year_matches = []\n",
    "\n",
    "    for match_id in tqdm(match_ids, desc=f\"  Merging matches for {year}\"):\n",
    "        file_a = os.path.join(year_path, match_id + 'a.csv')\n",
    "        file_b = os.path.join(year_path, match_id + 'b.csv')\n",
    "\n",
    "        try:\n",
    "            df_a = pd.read_csv(file_a)\n",
    "            df_b = pd.read_csv(file_b)\n",
    "\n",
    "            # Add metadata columns\n",
    "            df_a['innings'] = 1\n",
    "            df_b['innings'] = 2\n",
    "\n",
    "            df_a['match_id'] = match_id\n",
    "            df_b['match_id'] = match_id\n",
    "\n",
    "            match_df = pd.concat([df_a, df_b], ignore_index=True)\n",
    "            match_df['year'] = int(year)\n",
    "\n",
    "            year_matches.append(match_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing match {match_id} in {year}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Concatenate all matches of the year\n",
    "    if year_matches:\n",
    "        year_df = pd.concat(year_matches, ignore_index=True)\n",
    "        year_csv_path = os.path.join(output_path, f\"{year}.csv\")\n",
    "        year_df.to_csv(year_csv_path, index=False)\n",
    "        all_years_data.append(year_df)\n",
    "        print(f\"Saved {year_csv_path} with {len(year_df)} rows.\")\n",
    "    else:\n",
    "        print(f\"No valid matches found for year {year}.\")\n",
    "\n",
    "# Final merge of all years\n",
    "if all_years_data:\n",
    "    final_df = pd.concat(all_years_data, ignore_index=True)\n",
    "    final_output_file = os.path.join(base_path, 'all_years_combined.csv')\n",
    "    final_df.to_csv(final_output_file, index=False)\n",
    "    print(f\"\\n✅ Final combined dataset saved at: {final_output_file} with {len(final_df)} rows.\")\n",
    "else:\n",
    "    print(\"\\n❌ No data to combine for final CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34fb5e1a-71c3-45d8-89fe-ecdd7a4e2e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ball Number  over  ball  Ball       bowler bowler_role       batsman  \\\n",
      "0          0.1     0     1     1  Umesh Yadav     Bowlers  Rohit Sharma   \n",
      "1          0.2     0     2     2  Umesh Yadav     Bowlers  Rohit Sharma   \n",
      "2          0.3     0     3     3  Umesh Yadav     Bowlers   Aaron Finch   \n",
      "3          0.4     0     4     4  Umesh Yadav     Bowlers  Rohit Sharma   \n",
      "4          0.5     0     5     5  Umesh Yadav     Bowlers   Aaron Finch   \n",
      "\n",
      "  batsman_role  Runs  is_wicket  ...  total_overs  target runs_needed  \\\n",
      "0      Batters     0      False  ...           20     169         169   \n",
      "1      Batters     1      False  ...           20     169         168   \n",
      "2      Batters     1      False  ...           20     169         167   \n",
      "3      Batters     1      False  ...           20     169         166   \n",
      "4      Batters     1      False  ...           20     169         165   \n",
      "\n",
      "  overs_remaining required_run_rate  wickets_fallen  wickets_in_hand  \\\n",
      "0       19.833333          8.521008               0               10   \n",
      "1       19.666667          8.542373               0               10   \n",
      "2       19.500000          8.564103               0               10   \n",
      "3       19.333333          8.586207               0               10   \n",
      "4       19.166667          8.608696               0               10   \n",
      "\n",
      "   Ground_Type  innings  year  \n",
      "0        Large        1  2015  \n",
      "1        Large        1  2015  \n",
      "2        Large        1  2015  \n",
      "3        Large        1  2015  \n",
      "4        Large        1  2015  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "final_df = pd.read_csv(\"final.csv\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f75fea8-4f1e-4cf6-879e-c8fa1a5ca54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143823, 32)\n",
      "Ball Number               float64\n",
      "over                        int64\n",
      "ball                        int64\n",
      "Ball                        int64\n",
      "bowler                     object\n",
      "bowler_role                object\n",
      "batsman                    object\n",
      "batsman_role               object\n",
      "Runs                        int64\n",
      "is_wicket                    bool\n",
      "bowler_score              float64\n",
      "match_id                    int64\n",
      "city                       object\n",
      "stadium                    object\n",
      "Stadium_Type               object\n",
      "is_extra                     bool\n",
      "legal_delivery               bool\n",
      "legal_deliveries_count      int64\n",
      "overs_completed             int64\n",
      "overs_bowled              float64\n",
      "total_runs                  int64\n",
      "current_run_rate          float64\n",
      "total_overs                 int64\n",
      "target                      int64\n",
      "runs_needed                 int64\n",
      "overs_remaining           float64\n",
      "required_run_rate         float64\n",
      "wickets_fallen              int64\n",
      "wickets_in_hand             int64\n",
      "Ground_Type                object\n",
      "innings                     int64\n",
      "year                        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get the shape (rows, columns)\n",
    "print(final_df.shape)\n",
    "# Get the data types of each column\n",
    "print(final_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae45bd6b-ea5c-4f95-b178-a3e22026849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ball Number                  0\n",
      "over                         0\n",
      "ball                         0\n",
      "Ball                         0\n",
      "bowler                     341\n",
      "bowler_role               2933\n",
      "batsman                    341\n",
      "batsman_role               455\n",
      "Runs                         0\n",
      "is_wicket                    0\n",
      "bowler_score                 0\n",
      "match_id                     0\n",
      "city                         0\n",
      "stadium                    495\n",
      "Stadium_Type               495\n",
      "is_extra                     0\n",
      "legal_delivery               0\n",
      "legal_deliveries_count       0\n",
      "overs_completed              0\n",
      "overs_bowled                 0\n",
      "total_runs                   0\n",
      "current_run_rate             0\n",
      "total_overs                  0\n",
      "target                       0\n",
      "runs_needed                  0\n",
      "overs_remaining              0\n",
      "required_run_rate            0\n",
      "wickets_fallen               0\n",
      "wickets_in_hand              0\n",
      "Ground_Type                495\n",
      "innings                      0\n",
      "year                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "print(final_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09b1e2-c5fb-4aba-87a5-9f8374079d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
